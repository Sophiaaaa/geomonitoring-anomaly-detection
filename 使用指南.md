# 地质灾害监测异常检测系统使用指南

## 系统概述

本系统是专门为地质灾害监测数据开发的多维异常检测系统，支持7种类型的监测数据：

1. **泥水位监测** (dwd_mud_monitor_detail_di)
2. **倾角监测** (dwd_angle_monitor_detail_di)
3. **加速度监测** (dwd_acc_monitor_detail_di)
4. **GNSS位移监测** (dwd_gnss_monitor_detail_di)
5. **含水率监测** (dwd_moisture_monitor_detail_di)
6. **雨量监测** (dwd_rainfall_monitor_detail_di)
7. **裂缝监测** (dwd_crack_monitor_detail_di)

## 系统架构

```
geomonitoring-anomaly-detection/
├── src/                           # 核心代码
│   ├── hive_data_loader.py       # Hive数据加载器
│   ├── geological_anomaly_detector.py # 地质异常检测器
│   ├── main_analysis.py          # 主分析脚本
│   ├── preprocessing.py          # 数据预处理
│   └── decomposition.py          # 时间序列分解
├── notebooks/                    # Jupyter演示
├── config/                       # 配置文件
├── outputs/                      # 输出结果
└── data/                         # 数据目录
```

## 快速开始

### 1. 环境配置

```bash
# 创建conda环境
conda env create -f environment.yml
conda activate geomonitoring
```

### 2. 基本使用

```python
from src.hive_data_loader import HiveDataLoader
from src.geological_anomaly_detector import GeologicalAnomalyDetector

# 数据加载
loader = HiveDataLoader()
all_data = loader.load_all_tables()
feature_matrix = loader.get_feature_matrix(all_data)

# 异常检测
detector = GeologicalAnomalyDetector()
processed_features = detector.preprocess_features(feature_matrix)
anomaly_results = detector.detect_multivariate_anomalies(processed_features)

# 生成报告
report = detector.generate_anomaly_report(processed_features, anomaly_results)
```

### 3. 完整分析

```python
from src.main_analysis import GeologicalAnomalyAnalyzer

# 创建分析器
analyzer = GeologicalAnomalyAnalyzer()

# 运行完整分析
results = analyzer.run_complete_analysis(
    contamination=0.1,    # 异常值比例
    window_size=24       # 时间窗口大小
)

# 获取摘要
summary = analyzer.get_analysis_summary()
```

## 核心功能

### 1. 数据加载 (HiveDataLoader)

- **支持Hive数据源**：可连接真实Hive数据库
- **模拟数据生成**：无连接时自动生成测试数据
- **多表数据融合**：将7张表的数据合并为特征矩阵
- **时间范围过滤**：支持指定时间段的数据加载

**使用示例：**
```python
loader = HiveDataLoader(hive_connection=your_hive_conn)
data = loader.load_single_table("mud_monitor", 
                               start_time="2024-01-01 00:00:00",
                               end_time="2024-01-31 23:59:59")
```

### 2. 异常检测 (GeologicalAnomalyDetector)

#### 2.1 单变量异常检测
- **IQR方法**：四分位数范围异常检测
- **Z-Score方法**：标准分数异常检测
- **孤立森林方法**：基于隔离的异常检测

#### 2.2 多变量异常检测
- **孤立森林 (Isolation Forest)**：适用于高维数据
- **局部异常因子 (LOF)**：基于密度的异常检测
- **椭圆包络 (Elliptic Envelope)**：基于协方差的异常检测
- **DBSCAN聚类**：基于密度聚类的异常检测
- **集成方法**：多种方法投票决策

#### 2.3 时间序列异常检测
- **滑动窗口统计**：基于移动平均和标准差
- **季节性分解**：STL分解后的残差异常检测
- **趋势异常检测**：检测趋势变化异常

### 3. 特征分析

#### 3.1 特征重要性分析
```python
importance = detector.analyze_feature_importance(feature_matrix)
# 返回：{'mud_level_value': 0.85, 'angle_value_x': 0.72, ...}
```

#### 3.2 异常分数计算
- **标准化分数**：0-1范围的异常分数
- **异常等级**：低、中、高三个等级
- **综合评分**：多方法加权平均

### 4. 可视化功能

#### 4.1 异常检测结果图
- 散点图显示正常vs异常点
- 不同方法对比展示
- 异常分数分布图

#### 4.2 时间序列图
- 时间序列趋势图
- 异常点标记
- 滑动窗口统计

#### 4.3 特征重要性图
- 水平条形图
- 重要性排序
- 相关性热力图

## 配置选项

### 1. 区域配置 (config/regions.yaml)

```yaml
regions:
  north_china_plain:
    name: "华北平原"
    geometry:
      type: "rectangle"
      bounds: [114.0, 34.0, 120.0, 40.0]
    description: "华北平原地质灾害监测区域"
```

### 2. 异常检测参数

```python
# 异常检测参数
contamination = 0.1        # 异常值比例 (0.05-0.2)
window_size = 24          # 时间窗口大小 (12-48小时)
n_neighbors = 20          # LOF邻居数量
eps = 0.5                 # DBSCAN邻域半径
min_samples = 5           # DBSCAN最小样本数
```

## 输出结果

### 1. 报告文件
- **JSON报告**：`outputs/reports/analysis_report.json`
- **HTML报告**：`outputs/reports/analysis_report.html`
- **详细CSV**：`outputs/reports/detailed_results.csv`

### 2. 可视化图表
- **异常检测对比图**：`outputs/figures/anomaly_detection_comparison.png`
- **时间序列图**：`outputs/figures/time_series_anomalies.png`
- **特征重要性图**：`outputs/figures/feature_importance.png`
- **监测点分布图**：`outputs/figures/monitor_point_distribution.png`

### 3. 模型文件
- **训练好的模型**：保存在`outputs/models/`目录

## 高级用法

### 1. 连接真实Hive数据库

```python
# 配置Hive连接
import pydruid
from pyhive import hive

# 创建连接
conn = hive.Connection(
    host='your_hive_host',
    port=10000,
    database='your_database',
    username='your_username'
)

# 使用连接
loader = HiveDataLoader(hive_connection=conn)
```

### 2. 自定义异常检测算法

```python
class CustomAnomalyDetector(GeologicalAnomalyDetector):
    def custom_detection_method(self, data):
        # 实现自定义异常检测逻辑
        pass
```

### 3. 批量处理多个时间段

```python
import pandas as pd
from datetime import datetime, timedelta

# 按月批量处理
start_date = datetime(2024, 1, 1)
end_date = datetime(2024, 12, 31)

current_date = start_date
while current_date < end_date:
    month_end = current_date + timedelta(days=30)
    
    results = analyzer.run_complete_analysis(
        start_time=current_date.strftime('%Y-%m-%d %H:%M:%S'),
        end_time=month_end.strftime('%Y-%m-%d %H:%M:%S')
    )
    
    current_date = month_end
```

## 性能优化

### 1. 内存优化
- 使用数据分块处理大数据集
- 及时释放不需要的DataFrame
- 使用适当的数据类型

### 2. 计算优化
- 并行处理多个监测点
- 使用GPU加速（如果可用）
- 缓存预处理结果

### 3. 存储优化
- 使用Parquet格式存储中间结果
- 压缩输出文件
- 定期清理临时文件

## 故障排除

### 1. 常见错误

#### 数据加载错误
```
ERROR: 未提供Hive连接，使用模拟数据
```
**解决方案**：配置正确的Hive连接参数

#### 内存不足
```
ERROR: Memory allocation failed
```
**解决方案**：
- 减少数据量
- 增加系统内存
- 使用数据分块

#### 异常检测失败
```
ERROR: 'NoneType' object has no attribute 'split'
```
**解决方案**：
- 设置环境变量 `OPENBLAS_NUM_THREADS=1`
- 更新scikit-learn版本
- 检查数据质量

### 2. 性能问题

#### 处理速度慢
- 减少特征数量
- 调整算法参数
- 使用更快的算法

#### 内存使用过多
- 批量处理数据
- 使用内存映射文件
- 优化数据结构

## 最佳实践

### 1. 数据质量检查
- 定期检查数据完整性
- 处理缺失值和异常值
- 验证时间序列连续性

### 2. 模型调优
- 根据业务场景调整参数
- 定期重新训练模型
- 验证检测效果

### 3. 监控告警
- 设置异常率阈值
- 配置自动告警
- 定期生成报告

## 扩展功能

### 1. 实时监测
- 集成流式数据处理
- 实时异常检测
- 在线模型更新

### 2. 深度学习
- 集成深度学习模型
- 自动特征提取
- 端到端训练

### 3. 可视化界面
- Web界面开发
- 交互式图表
- 实时监控面板

## 技术支持

如有问题，请提供以下信息：
- 错误信息完整日志
- 数据规模和特征描述
- 系统环境信息
- 使用的参数配置

## 更新日志

### v1.0.0 (2024-01-01)
- 基础异常检测功能
- 7种监测数据支持
- 可视化报告生成

### v1.1.0 (计划中)
- 实时监测功能
- 深度学习模型集成
- 性能优化 